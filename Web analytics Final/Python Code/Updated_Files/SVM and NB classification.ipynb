{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dtm: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "size of tfidf matrix: (257, 8846)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Matrix\n",
    "with open('C:/Users/rajpu/Desktop/Web analytics Final/Python Code/Updated_Files/Updated Wall_Street.csv', 'r') as f:\n",
    "    data = [tuple(line) for line in csv.reader(f)]\n",
    "    \n",
    "Title,entryDate,Label,Articles=zip(*data)\n",
    "\n",
    "#date=list(Date)\n",
    "news=list(Articles)\n",
    "sent=list(Label)\n",
    "#lab=list(Lable)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer() \n",
    "tfidf_vect = TfidfVectorizer(stop_words=\"english\") \n",
    "\n",
    "dtm= tfidf_vect.fit_transform(news)\n",
    "\n",
    "print(\"type of dtm:\", type(dtm))\n",
    "print(\"size of tfidf matrix:\", dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of vocabulary: <class 'dict'>\n",
      "index of word 'city' in vocabulary: 1653\n",
      "total number of words: 8846\n",
      "\n",
      "Original text: \n",
      "Wells Fargo & Co.'s board stripped eight top executives of 2016 cash bonuses and clawed back certain stock awards in response to the bank's sales-practices scandal.The San Francisco-based lender said Wednesday that the compensation cuts for current executives don't reflect the culpability of individuals but are meant to show their accountability for the bank's overall performance and reputational risk as a result of the scandal.Eight of Wells Fargo's executives, including current Chief Executive Officer Timothy Sloan and financial chief John Shrewsberry, are affected by the moves, resulting in a loss of total compensation of about $32 million.Mr. Sloan didn't become chief executive until October when former CEO John Stumpf abruptly retired following congressional grillings and a public uproar over the sales-practices scandal that also cost the bank a $185 million settlement.Before this, Mr. Sloan was the bank's president and chief operating officer.In addition to the bonus cut, the company also said it would claw back up to 50% of the compensation the executives would have received from certain shares granted in 2014.The shares, which were tied to the company's performance, are part of executives' long-term equity incentives.In 2015, Mr. Sloan received performance share awards valued at $6.5 million, according to the bank's most recent proxy statement.Wells Fargo's board in late September rescinded a total of about $60 million in pay from Mr. Stumpf and then-retail-bank head Carrie Tolstedt.Wells Fargo also said Wednesday in its annual securities filing that more customers may have been affected by the scandal than it initially disclosed. In its September settlement, the bank, regulators and a city official said up to 2.1 million accounts were opened using fictitious or unauthorized customer information.The bank didn't give further detail on how much higher that number could be. It added in the filing that this is unlikely to significantly affect customer refund costs.The board's investigation into the scandal is continuing, and the bank reiterated it is expected to be completed before its annual shareholder meeting expected in late April.While it is unusual for banks to withhold bonuses from top executives -- incentive compensation makes up the bulk of their pay -- it has become more common in recent years.\n",
      "\n",
      "tfidf weights: \n",
      "\n",
      "(8846,)\n",
      "[('articles', 1.0), ('zurich', 0.0), ('eqt', 0.0), ('equitable', 0.0), ('equipped', 0.0), ('equipment', 0.0), ('equilibrium', 0.0), ('equifax', 0.0), ('equal', 0.0), ('episodes', 0.0), ('episode', 0.0), ('epicenter', 0.0), ('epfr', 0.0), ('environments', 0.0), ('environment', 0.0), ('enveloping', 0.0), ('equities', 0.0), ('equity', 0.0), ('equivalent', 0.0), ('era', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "print(\"type of vocabulary:\", type(tfidf_vect.vocabulary_))\n",
    "print(\"index of word 'city' in vocabulary:\", \\\n",
    "      tfidf_vect.vocabulary_['city'])\n",
    "voc_lookup={tfidf_vect.vocabulary_[word]:word \\\n",
    "            for word in tfidf_vect.vocabulary_}\n",
    "print(\"total number of words:\", len(voc_lookup ))\n",
    "\n",
    "print(\"\\nOriginal text: \\n\"+news[1])\n",
    "\n",
    "print(\"\\ntfidf weights: \\n\")\n",
    "doc0=dtm[0].toarray()[0]\n",
    "print(doc0.shape)\n",
    "\n",
    "\n",
    "top_words=(doc0.argsort())[::-1][0:20]\n",
    "print([(voc_lookup[i], doc0[i]) for i in top_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "                  0.00      0.00      0.00         4\n",
      "          0       0.71      0.19      0.29        27\n",
      "          1       0.63      0.96      0.76        47\n",
      "\n",
      "avg / total       0.63      0.64      0.56        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1428: UserWarning: labels size, 3, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, sent, test_size=0.3, random_state=0)\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "labels=sorted(list(set(sent)))\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(\\\n",
    "     y_test, predicted, labels=labels)\n",
    "    \n",
    "#print(precision)\n",
    "#print(recall)\n",
    "#print(fscore)\n",
    "#print(support)\n",
    "\n",
    "print(classification_report(y_test, predicted, target_names=labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[ 0.22333333  0.52941176  0.41950113  0.53741497  0.45740741]\n",
      "\n",
      "Test data set average recall:\n",
      "[ 0.24722222  0.35185185  0.35925926  0.37037037  0.38066261]\n",
      "\n",
      "Test data set average fscore:\n",
      "[ 0.19880952  0.2820013   0.3082178   0.31983122  0.34749035]\n",
      "\n",
      " Train data set average fscore:\n",
      "[ 0.5087386   0.36586979  0.34761905  0.33301727  0.36445899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "\n",
    "clf = MultinomialNB()\n",
    "#clf = MultinomialNB(alpha=0.8)\n",
    "\n",
    "cv = cross_validate(clf, dtm, sent, scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n",
    "\n",
    "# To see the performance of training data set use \n",
    "#cv['train_xx_macro']\n",
    "print(\"\\n Train data set average fscore:\")\n",
    "print(cv['train_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[ 0.51932773  0.74332172  0.7254902   0.85416667  0.66011396]\n",
      "\n",
      "Test data set average recall:\n",
      "[ 0.56111111  0.70740741  0.71851852  0.84444444  0.77890467]\n",
      "\n",
      "Test data set average fscore:\n",
      "[ 0.53472222  0.69352113  0.71875     0.84819734  0.70194805]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#SVM model\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "\n",
    "# initiate an linear SVM model\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "cv = cross_validate(clf, dtm, sent, scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "                  0.80      1.00      0.89         4\n",
      "          0       0.43      0.33      0.38        27\n",
      "          1       0.65      0.72      0.69        47\n",
      "\n",
      "avg / total       0.58      0.60      0.59        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\rajpu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1428: UserWarning: labels size, 3, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, sent, test_size=0.3, random_state=0)\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "#clf = MultinomialNB().fit(X_train, y_train)\n",
    "clf = svm.LinearSVC().fit(X_train, y_train)\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "labels=sorted(list(set(sent)))\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(\\\n",
    "     y_test, predicted, labels=labels)\n",
    "    \n",
    "#print(precision)\n",
    "#print(recall)\n",
    "#print(fscore)\n",
    "#print(support)\n",
    "\n",
    "print(classification_report(y_test, predicted, target_names=labels))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
