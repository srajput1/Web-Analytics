{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 2, 'world!': 1, 'this': 1, 'is': 1, 'world': 1, 'example': 1}\n"
     ]
    }
   ],
   "source": [
    "#Sourabh Rajput\n",
    "#BIA 660 C\n",
    "#CWID 10431188\n",
    "\n",
    "\n",
    "# Structure of your solution to Assignment 1 \n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    " \n",
    "def count_token(text):  #Function Count_token, text is a parameter passed from main\n",
    "    \n",
    "    \n",
    "      \n",
    "    t = text.split(' ') #splits the string into a list of tokens by space\n",
    "    tp = []\n",
    "    token_count = dict()\n",
    "    for i in t:\n",
    "        i.strip()       #strips all leading and trailing space of each token\n",
    "        i = i.replace('\\n','') \n",
    "        if len(i) > 1: #removes a token if it contain no more than 1 character\n",
    "            tp.append(i.lower()) #converts all tokens into lower case\n",
    "   \n",
    "    for i in tp:    #counts every remaining token\n",
    "        if i in token_count:\n",
    "            token_count[i] += 1\n",
    "        else:\n",
    "            token_count[i] = 1\n",
    "\n",
    "     \n",
    "     \n",
    "    return token_count        #returns the dictionary\n",
    "\n",
    "class Text_Analyzer(object):  #class Text_Analyzer\n",
    "    \n",
    "    def __init__(self, input_file, output_file): # input and out put files initialize with constructor\n",
    "        self.input_file=input_file \n",
    "        self.output_file=output_file\n",
    "        \n",
    "    def analyze(self):    #function Analyze\n",
    "        ReadFile = open(self.input_file,\"r\") \n",
    "        res=ReadFile.readlines(); #reads all lines from input_file\n",
    "        str1 = ' '.join(res) #concatenate them into a string\n",
    "        ReadFile.close()\n",
    "        \n",
    "        CallFunction={}\n",
    "        CallFunction=count_token(str1) #calls the function \"count_token\"\n",
    "         #saves the dictionary into output_file with each key-value pair as a line delimited by comma\n",
    "        rows = list(CallFunction.items())\n",
    "        with open(\"foo.csv\", \"w\") as f:  \n",
    "            writer=csv.writer(f, delimiter=\",\")\n",
    "            writer.writerows(rows)\n",
    "        # add your code\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    text='''Hello world!\n",
    "        This is a hello world example !'''   \n",
    "    print(count_token(text))\n",
    "    \n",
    "    # # The output of your text should be: \n",
    "    # {'this': 1, 'is': 1, 'example': 1, 'world!': 1, 'world': 1, 'hello': 2}\n",
    "    \n",
    "# Test Question 2\n",
    "    analyzer=Text_Analyzer(\"foo.txt\", \"foo.csv\")\n",
    "    vocabulary=analyzer.analyze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
